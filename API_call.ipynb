{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "z = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\Sourcing\\\\pconf.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    ").fillna(\"\")\n",
    "s = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\ama.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    ").fillna(\"\")\n",
    "# acct = pd.read_csv(\n",
    "#    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\acct_npi.csv\",\n",
    "#    low_memory=False,\n",
    "#    index_col=False,\n",
    "#    encoding=\"unicode_escape\",\n",
    "# ).fillna(\"\")\n",
    "cross = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\cross_npi.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=\"object\",\n",
    ").fillna(\"\")\n",
    "\n",
    "\n",
    "cross = cross[cross[\"NPI\"] != \"\"]\n",
    "# acct1 = acct[acct[\"Person Account: NPI Number\"] != \"\"]\n",
    "s.rename(columns={\"AMA Specialty: AMA Specialty Name\": \"Specialization\"})\n",
    "s = s.drop_duplicates()\n",
    "s1 = s[s[\"Taxonomy Code\"] != \"\"]\n",
    "\n",
    "\n",
    "errors = []\n",
    "data = []\n",
    "\n",
    "# merge = pd.concat([a,b,c], ignore_index=True)\n",
    "# file1 = merge[(merge['Mail Name'] != '© 2023 by the American Medical Association') & merge['Mail Name'] != 'Â© 2023 by the American Medical Association']\n",
    "# file1 = file1[['Mail  Last Name', 'Mail First Name', 'MD-DO Flag', 'City', 'State', 'Zip', 'Primary Specialty']]\n",
    "# file = file1.rename(\n",
    "#    columns = {'Mail  Last Name': 'last_name',\n",
    "#            'Mail First Name': 'first_name',\n",
    "#            'Mail City': 'City',\n",
    "#            'State': 'state',\n",
    "#            'Zip': 'Postal Code',\n",
    "#            'MD-DO Flag': 'Practitioner Type'\n",
    "#            })\n",
    "data_dfs = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"number\",\n",
    "        \"First Name\",\n",
    "        \"Last Name\",\n",
    "        \"Gender\",\n",
    "        \"basic.enumeration_date\",\n",
    "        \"country_name\",\n",
    "        \"address_purpose\",\n",
    "        \"address_1\",\n",
    "        \"city\",\n",
    "        \"state_x\",\n",
    "        \"postal_code\",\n",
    "        \"telephone_number\",\n",
    "        \"code\",\n",
    "        \"taxonomy_group\",\n",
    "        \"desc\",\n",
    "        \"state_y\",\n",
    "        \"license\",\n",
    "        \"primary\",\n",
    "    ]\n",
    ").fillna(\"\")\n",
    "\n",
    "data_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"number\",\n",
    "        \"First Name\",\n",
    "        \"Last Name\",\n",
    "        \"Gender\",\n",
    "        \"basic.enumeration_date\",\n",
    "        \"country_name\",\n",
    "        \"address_purpose\",\n",
    "        \"address_1\",\n",
    "        \"city\",\n",
    "        \"state_x\",\n",
    "        \"postal_code\",\n",
    "        \"telephone_number\",\n",
    "        \"code\",\n",
    "        \"taxonomy_group\",\n",
    "        \"desc\",\n",
    "        \"state_y\",\n",
    "        \"license\",\n",
    "        \"primary\",\n",
    "    ]\n",
    ").fillna(\"\")\n",
    "\n",
    "url = \"https://npiregistry.cms.hhs.gov/api/?version=2.1\"\n",
    "\n",
    "\n",
    "file = z.fillna(\"\")\n",
    "\n",
    "file_df = file[[\"First Name\", \"Last Name\"]]\n",
    "\n",
    "for row in file_df.index:\n",
    "    first_name, last_name = (\n",
    "        file_df[\"First Name\"][row],\n",
    "        file_df[\"Last Name\"][row],\n",
    "    )\n",
    "    # file_df[\"Last Name\"].str[:2][row]\n",
    "    parameters = {\n",
    "        \"version\": \"2.1\",\n",
    "        \"first_name\": first_name,\n",
    "        \"last_name\": last_name,\n",
    "        \"pretty\": \"true\",\n",
    "    }\n",
    "\n",
    "    # raises exception when not a 2xx response\n",
    "\n",
    "    response = requests.get(url, params=parameters).json()\n",
    "    # response.raise_for_status()\n",
    "    #\n",
    "    # if response.status_code != 204:\n",
    "    #    return response.json()\n",
    "    for i in response:\n",
    "        if i == \"result_count\":\n",
    "            if response[\"result_count\"] < 1:\n",
    "                errors.append(parameters)\n",
    "            elif response[\"result_count\"] >= 1:\n",
    "                data.append(response)\n",
    "        else:\n",
    "            errors.append(parameters)\n",
    "    for l in data:\n",
    "        data1 = pd.json_normalize(\n",
    "            l[\"results\"], \"addresses\", [\"number\", \"enumeration_type\"]\n",
    "        )\n",
    "        data1 = data1.drop_duplicates(subset=\"number\")\n",
    "        data2 = pd.json_normalize(l[\"results\"], \"taxonomies\", [\"number\"])\n",
    "        data4 = pd.json_normalize(l[\"results\"])\n",
    "        file1 = pd.merge_ordered(data1, data2, on=\"number\", how=\"outer\")\n",
    "        file2 = pd.merge_ordered(file1, data4, on=\"number\", how=\"outer\")\n",
    "\n",
    "        file3 = file2[\n",
    "            [\n",
    "                \"number\",\n",
    "                \"basic.first_name\",\n",
    "                \"basic.last_name\",\n",
    "                \"basic.gender\",\n",
    "                \"basic.enumeration_date\",\n",
    "                \"country_name\",\n",
    "                \"address_purpose\",\n",
    "                \"address_1\",\n",
    "                \"city\",\n",
    "                \"state_x\",\n",
    "                \"postal_code\",\n",
    "                \"telephone_number\",\n",
    "                \"code\",\n",
    "                \"taxonomy_group\",\n",
    "                \"desc\",\n",
    "                \"state_y\",\n",
    "                \"license\",\n",
    "                \"primary\",\n",
    "            ]\n",
    "        ]\n",
    "        file4a = file3.rename(\n",
    "            columns={\n",
    "                \"basic.first_name\": \"First Name\",\n",
    "                \"basic.last_name\": \"Last Name\",\n",
    "                \"basic.middle_name\": \"Middle Name\",\n",
    "                \"basic.credential\": \"Practitioner Type\",\n",
    "                \"basic.gender\": \"Gender\",\n",
    "            }\n",
    "        ).drop_duplicates(subset=\"number\")\n",
    "\n",
    "        file4b = pd.merge_ordered(\n",
    "            file4a, cross, left_on=\"number\", right_on=\"NPI\", how=\"left\"\n",
    "        ).fillna(\"\")\n",
    "        file4c = pd.merge_ordered(\n",
    "            file4b, s1, left_on=\"code\", right_on=\"Taxonomy Code\", how=\"left\"\n",
    "        ).fillna(\"\")\n",
    "        file4 = file4c[file4c[\"AMA Specialty: AMA Specialty Name\"] != \"\"]\n",
    "\n",
    "        if len(data_df) < 500:\n",
    "            data_df = pd.concat([data_df, file4]).drop_duplicates(subset=\"number\")\n",
    "        elif len(data_df) >= 500:\n",
    "            data_df.to_csv(\"e2.csv\", index=False)\n",
    "            data_df1 = pd.concat([data_df1, file4])\n",
    "            data_df1 = data_df1.drop_duplicates(subset=\"number\")\n",
    "        else:\n",
    "            data_df1.to_csv(\"e3.csv\", index=False)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################1\n",
    "import pandas as pd\n",
    "\n",
    "ama = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\ama.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=object,\n",
    ").fillna(\"\")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\mihma\\\\OneDrive\\\\Desktop\\\\Data Work\\\\sand.csv\",\n",
    "    usecols=[\n",
    "        \"NPI\",\n",
    "        \"Entity Type Code\",\n",
    "        \"Provider Organization Name (Legal Business Name)\",\n",
    "        \"Provider Last Name (Legal Name)\",\n",
    "        \"Provider First Name\",\n",
    "        \"Provider Middle Name\",\n",
    "        \"Provider Credential Text\",\n",
    "        \"Provider First Line Business Mailing Address\",\n",
    "        \"Provider Second Line Business Mailing Address\",\n",
    "        \"Provider Business Practice Location Address City Name\",\n",
    "        \"Provider Business Practice Location Address State Name\",\n",
    "        \"Provider Business Practice Location Address Postal Code\",\n",
    "        \"Provider Business Practice Location Address Country Code (If outside U.S.)\",\n",
    "        \"Provider Business Practice Location Address Telephone Number\",\n",
    "        \"Provider Business Practice Location Address Fax Number\",\n",
    "        \"Provider Enumeration Date\",\n",
    "        \"NPI Deactivation Date\",\n",
    "        \"NPI Reactivation Date\",\n",
    "        \"Provider Gender Code\",\n",
    "        \"Authorized Official Last Name\",\n",
    "        \"Authorized Official First Name\",\n",
    "        \"Authorized Official Middle Name\",\n",
    "        \"Authorized Official Title or Position\",\n",
    "        \"Authorized Official Telephone Number\",\n",
    "        \"Healthcare Provider Taxonomy Code_1\",\n",
    "        \"Provider License Number_1\",\n",
    "        \"Provider License Number State Code_1\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_1\",\n",
    "        \"Healthcare Provider Taxonomy Code_2\",\n",
    "        \"Provider License Number_2\",\n",
    "        \"Provider License Number State Code_2\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_2\",\n",
    "        \"Healthcare Provider Taxonomy Code_3\",\n",
    "        \"Provider License Number_3\",\n",
    "        \"Provider License Number State Code_3\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_3\",\n",
    "        \"Healthcare Provider Taxonomy Code_4\",\n",
    "        \"Provider License Number_4\",\n",
    "        \"Provider License Number State Code_4\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_4\",\n",
    "        \"Healthcare Provider Taxonomy Code_5\",\n",
    "        \"Provider License Number_5\",\n",
    "        \"Provider License Number State Code_5\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_5\",\n",
    "        \"Healthcare Provider Taxonomy Code_6\",\n",
    "        \"Provider License Number_6\",\n",
    "        \"Provider License Number State Code_6\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_6\",\n",
    "        \"Healthcare Provider Taxonomy Code_7\",\n",
    "        \"Provider License Number_7\",\n",
    "        \"Provider License Number State Code_7\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_7\",\n",
    "        \"Healthcare Provider Taxonomy Code_8\",\n",
    "        \"Provider License Number_8\",\n",
    "        \"Provider License Number State Code_8\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_8\",\n",
    "        \"Healthcare Provider Taxonomy Code_9\",\n",
    "        \"Provider License Number_9\",\n",
    "        \"Provider License Number State Code_9\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_9\",\n",
    "        \"Healthcare Provider Taxonomy Code_10\",\n",
    "        \"Provider License Number_10\",\n",
    "        \"Provider License Number State Code_10\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_10\",\n",
    "        \"Healthcare Provider Taxonomy Code_11\",\n",
    "        \"Provider License Number_11\",\n",
    "        \"Provider License Number State Code_11\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_11\",\n",
    "        \"Healthcare Provider Taxonomy Code_12\",\n",
    "        \"Provider License Number_12\",\n",
    "        \"Provider License Number State Code_12\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_12\",\n",
    "        \"Healthcare Provider Taxonomy Code_13\",\n",
    "        \"Provider License Number_13\",\n",
    "        \"Provider License Number State Code_13\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_13\",\n",
    "        \"Healthcare Provider Taxonomy Code_14\",\n",
    "        \"Provider License Number_14\",\n",
    "        \"Provider License Number State Code_14\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_14\",\n",
    "        \"Healthcare Provider Taxonomy Code_15\",\n",
    "        \"Provider License Number_15\",\n",
    "        \"Provider License Number State Code_15\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_15\",\n",
    "    ],\n",
    "    chunksize=100000,\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=object,\n",
    ")  # .fillna(\"\")\n",
    "for ch in df:\n",
    "    sand = pd.concat(df).fillna(\"\")\n",
    "t2 = sand[sand[\"Entity Type Code\"] == \"2\"]\n",
    "p1 = sand[sand[\"Entity Type Code\"] == \"1\"]\n",
    "s = sand[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Taxonomy Code_1\",\n",
    "        \"Provider License Number_1\",\n",
    "        \"Provider License Number State Code_1\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_1\",\n",
    "        \"Healthcare Provider Taxonomy Code_2\",\n",
    "        \"Provider License Number_2\",\n",
    "        \"Provider License Number State Code_2\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_2\",\n",
    "        \"Healthcare Provider Taxonomy Code_3\",\n",
    "        \"Provider License Number_3\",\n",
    "        \"Provider License Number State Code_3\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_3\",\n",
    "        \"Healthcare Provider Taxonomy Code_4\",\n",
    "        \"Provider License Number_4\",\n",
    "        \"Provider License Number State Code_4\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_4\",\n",
    "        \"Healthcare Provider Taxonomy Code_5\",\n",
    "        \"Provider License Number_5\",\n",
    "        \"Provider License Number State Code_5\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_5\",\n",
    "        \"Healthcare Provider Taxonomy Code_6\",\n",
    "        \"Provider License Number_6\",\n",
    "        \"Provider License Number State Code_6\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_6\",\n",
    "        \"Healthcare Provider Taxonomy Code_7\",\n",
    "        \"Provider License Number_7\",\n",
    "        \"Provider License Number State Code_7\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_7\",\n",
    "        \"Healthcare Provider Taxonomy Code_8\",\n",
    "        \"Provider License Number_8\",\n",
    "        \"Provider License Number State Code_8\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_8\",\n",
    "        \"Healthcare Provider Taxonomy Code_9\",\n",
    "        \"Provider License Number_9\",\n",
    "        \"Provider License Number State Code_9\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_9\",\n",
    "        \"Healthcare Provider Taxonomy Code_10\",\n",
    "        \"Provider License Number_10\",\n",
    "        \"Provider License Number State Code_10\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_10\",\n",
    "        \"Healthcare Provider Taxonomy Code_11\",\n",
    "        \"Provider License Number_11\",\n",
    "        \"Provider License Number State Code_11\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_11\",\n",
    "        \"Healthcare Provider Taxonomy Code_12\",\n",
    "        \"Provider License Number_12\",\n",
    "        \"Provider License Number State Code_12\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_12\",\n",
    "        \"Healthcare Provider Taxonomy Code_13\",\n",
    "        \"Provider License Number_13\",\n",
    "        \"Provider License Number State Code_13\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_13\",\n",
    "        \"Healthcare Provider Taxonomy Code_14\",\n",
    "        \"Provider License Number_14\",\n",
    "        \"Provider License Number State Code_14\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_14\",\n",
    "        \"Healthcare Provider Taxonomy Code_15\",\n",
    "        \"Provider License Number_15\",\n",
    "        \"Provider License Number State Code_15\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_15\",\n",
    "    ]\n",
    "]\n",
    "p1 = p1[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Entity Type Code\",\n",
    "        \"Provider Organization Name (Legal Business Name)\",\n",
    "        \"Provider Last Name (Legal Name)\",\n",
    "        \"Provider First Name\",\n",
    "        \"Provider Middle Name\",\n",
    "        \"Provider Credential Text\",\n",
    "        \"Provider First Line Business Mailing Address\",\n",
    "        \"Provider Second Line Business Mailing Address\",\n",
    "        \"Provider Business Practice Location Address City Name\",\n",
    "        \"Provider Business Practice Location Address State Name\",\n",
    "        \"Provider Business Practice Location Address Postal Code\",\n",
    "        \"Provider Business Practice Location Address Country Code (If outside U.S.)\",\n",
    "        \"Provider Business Practice Location Address Telephone Number\",\n",
    "        \"Provider Business Practice Location Address Fax Number\",\n",
    "        \"Provider Enumeration Date\",\n",
    "        \"NPI Deactivation Date\",\n",
    "        \"NPI Reactivation Date\",\n",
    "        \"Provider Gender Code\",\n",
    "        \"Provider License Number State Code_1\",\n",
    "        \"Provider License Number State Code_2\",\n",
    "        \"Provider License Number State Code_3\",\n",
    "        \"Provider License Number State Code_4\",\n",
    "        \"Provider License Number State Code_5\",\n",
    "        \"Provider License Number State Code_6\",\n",
    "        \"Provider License Number State Code_7\",\n",
    "        \"Provider License Number State Code_8\",\n",
    "        \"Provider License Number State Code_9\",\n",
    "        \"Provider License Number State Code_10\",\n",
    "        \"Provider License Number State Code_11\",\n",
    "        \"Provider License Number State Code_12\",\n",
    "        \"Provider License Number State Code_13\",\n",
    "        \"Provider License Number State Code_14\",\n",
    "        \"Provider License Number State Code_15\",\n",
    "    ]\n",
    "].fillna(\"\")\n",
    "\n",
    "p1[\"Gender\"] = p1[\"Provider Gender Code\"].replace({\"F\": \"Female\", \"M\": \"Male\"})\n",
    "\n",
    "p1[\"License (Active)\"] = (\n",
    "    p1[\n",
    "        [\n",
    "            \"Provider License Number State Code_1\",\n",
    "            \"Provider License Number State Code_2\",\n",
    "            \"Provider License Number State Code_3\",\n",
    "            \"Provider License Number State Code_4\",\n",
    "            \"Provider License Number State Code_5\",\n",
    "            \"Provider License Number State Code_6\",\n",
    "            \"Provider License Number State Code_7\",\n",
    "            \"Provider License Number State Code_8\",\n",
    "            \"Provider License Number State Code_9\",\n",
    "            \"Provider License Number State Code_10\",\n",
    "            \"Provider License Number State Code_11\",\n",
    "            \"Provider License Number State Code_12\",\n",
    "            \"Provider License Number State Code_13\",\n",
    "            \"Provider License Number State Code_14\",\n",
    "            \"Provider License Number State Code_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .astype(\"str\")\n",
    "    .agg(\";\".join, axis=1)\n",
    "    .drop_duplicates()\n",
    "    .fillna(\"\")\n",
    ")\n",
    "p1[\"License (Active)\"] = (\n",
    "    p1[\"License (Active)\"]\n",
    "    .replace(\n",
    "        {\n",
    "            \";;;;;;;;;;;;;;$\": \"\",\n",
    "            \";;;;;;;;;;;;;$\": \"\",\n",
    "            \";;;;;;;;;;;;$\": \"\",\n",
    "            \";;;;;;;;;;;$\": \"\",\n",
    "            \";;;;;;;;;;$\": \"\",\n",
    "            \";;;;;;;;;$\": \"\",\n",
    "            \";;;;;;;;$\": \"\",\n",
    "            \";;;;;;;$\": \"\",\n",
    "            \";;;;;;$\": \"\",\n",
    "            \";;;;;$\": \"\",\n",
    "            \";;;;$\": \"\",\n",
    "            \";;;$\": \"\",\n",
    "            \";;$\": \"\",\n",
    "            \";$\": \"\",\n",
    "            \"^;;;;;;;;;;;;;;\": \"\",\n",
    "            \"^;;;;;;;;;;;;;\": \"\",\n",
    "            \"^;;;;;;;;;;;;$\": \"\",\n",
    "            \"^;;;;;;;;;;;\": \"\",\n",
    "            \"^;;;;;;;;;;\": \"\",\n",
    "            \"^;;;;;;;;;\": \"\",\n",
    "            \"^;;;;;;;;\": \"\",\n",
    "            \"^;;;;;;;\": \"\",\n",
    "            \"^;;;;;;\": \"\",\n",
    "            \"^;;;;;\": \"\",\n",
    "            \"^;;;;\": \"\",\n",
    "            \"^;;;\": \"\",\n",
    "            \"^;;\": \"\",\n",
    "            \"^;\": \"\",\n",
    "        },\n",
    "        regex=True,\n",
    "    )\n",
    "    .fillna(\"\")\n",
    ")\n",
    "p2 = p1[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Gender\",\n",
    "        \"Entity Type Code\",\n",
    "        \"Provider Organization Name (Legal Business Name)\",\n",
    "        \"Provider Last Name (Legal Name)\",\n",
    "        \"Provider First Name\",\n",
    "        \"Provider Middle Name\",\n",
    "        \"Provider Credential Text\",\n",
    "        \"Provider First Line Business Mailing Address\",\n",
    "        \"Provider Second Line Business Mailing Address\",\n",
    "        \"Provider Business Practice Location Address City Name\",\n",
    "        \"Provider Business Practice Location Address State Name\",\n",
    "        \"Provider Business Practice Location Address Postal Code\",\n",
    "        \"Provider Business Practice Location Address Country Code (If outside U.S.)\",\n",
    "        \"Provider Business Practice Location Address Telephone Number\",\n",
    "        \"Provider Business Practice Location Address Fax Number\",\n",
    "        \"Provider Enumeration Date\",\n",
    "        \"NPI Deactivation Date\",\n",
    "        \"NPI Reactivation Date\",\n",
    "        \"License (Active)\",\n",
    "        \"Provider Gender Code\",\n",
    "    ]\n",
    "]\n",
    "t3 = t2[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Entity Type Code\",\n",
    "        \"Provider Credential Text\",\n",
    "        \"Provider First Line Business Mailing Address\",\n",
    "        \"Provider Second Line Business Mailing Address\",\n",
    "        \"Provider Business Practice Location Address City Name\",\n",
    "        \"Provider Business Practice Location Address State Name\",\n",
    "        \"Provider Business Practice Location Address Postal Code\",\n",
    "        \"Provider Business Practice Location Address Country Code (If outside U.S.)\",\n",
    "        \"Provider Business Practice Location Address Telephone Number\",\n",
    "        \"Provider Enumeration Date\",\n",
    "        \"Authorized Official Last Name\",\n",
    "        \"Authorized Official First Name\",\n",
    "        \"Authorized Official Middle Name\",\n",
    "        \"Authorized Official Title or Position\",\n",
    "        \"Authorized Official Telephone Number\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "s1 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_1\",\n",
    "        \"Healthcare Provider Taxonomy Code_1\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_1\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_1\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s2 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_2\",\n",
    "        \"Healthcare Provider Taxonomy Code_2\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_2\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_2\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s3 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_3\",\n",
    "        \"Healthcare Provider Taxonomy Code_3\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_3\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_3\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s4 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_4\",\n",
    "        \"Healthcare Provider Taxonomy Code_4\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_4\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_4\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s5 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_5\",\n",
    "        \"Healthcare Provider Taxonomy Code_5\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_5\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_5\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s6 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_6\",\n",
    "        \"Healthcare Provider Taxonomy Code_6\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_6\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_6\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s7 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_7\",\n",
    "        \"Healthcare Provider Taxonomy Code_7\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_7\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_7\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s8 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_8\",\n",
    "        \"Healthcare Provider Taxonomy Code_8\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_8\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_8\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s9 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_9\",\n",
    "        \"Healthcare Provider Taxonomy Code_9\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_9\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_9\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s10 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_10\",\n",
    "        \"Healthcare Provider Taxonomy Code_10\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_10\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_10\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s11 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_11\",\n",
    "        \"Healthcare Provider Taxonomy Code_11\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_11\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_11\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s12 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_12\",\n",
    "        \"Healthcare Provider Taxonomy Code_12\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_12\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_12\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s13 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_13\",\n",
    "        \"Healthcare Provider Taxonomy Code_13\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_13\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_13\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s14 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_14\",\n",
    "        \"Healthcare Provider Taxonomy Code_14\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_14\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_14\": \"switch\",\n",
    "    }\n",
    ")\n",
    "s15 = s[\n",
    "    [\n",
    "        \"NPI\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_15\",\n",
    "        \"Healthcare Provider Taxonomy Code_15\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"Healthcare Provider Taxonomy Code_15\": \"code\",\n",
    "        \"Healthcare Provider Primary Taxonomy Switch_15\": \"switch\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "s1 = s1[s1[\"switch\"] == \"Y\"]\n",
    "s2 = s2[s2[\"switch\"] == \"Y\"]\n",
    "s3 = s3[s3[\"switch\"] == \"Y\"]\n",
    "s4 = s4[s4[\"switch\"] == \"Y\"]\n",
    "s5 = s5[s5[\"switch\"] == \"Y\"]\n",
    "s6 = s6[s6[\"switch\"] == \"Y\"]\n",
    "s7 = s7[s7[\"switch\"] == \"Y\"]\n",
    "s8 = s8[s8[\"switch\"] == \"Y\"]\n",
    "s9 = s9[s9[\"switch\"] == \"Y\"]\n",
    "s10 = s10[s10[\"switch\"] == \"Y\"]\n",
    "s11 = s11[s11[\"switch\"] == \"Y\"]\n",
    "s12 = s12[s12[\"switch\"] == \"Y\"]\n",
    "s13 = s13[s13[\"switch\"] == \"Y\"]\n",
    "s14 = s14[s14[\"switch\"] == \"Y\"]\n",
    "s15 = s15[s15[\"switch\"] == \"Y\"]\n",
    "\n",
    "##############2\n",
    "sss = pd.concat([s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11, s12, s13, s14, s15])\n",
    "\n",
    "t4 = pd.merge_ordered(t3, sss, on=\"NPI\", how=\"left\")\n",
    "p3 = pd.merge_ordered(p2, sss, on=\"NPI\", how=\"left\")\n",
    "\n",
    "\n",
    "############1\n",
    "t4.drop_duplicates(subset=\"NPI\")\n",
    "p3.drop_duplicates(subset=\"NPI\")\n",
    "t5 = pd.merge_ordered(\n",
    "    t4, ama, left_on=\"code\", right_on=\"Taxonomy Code\", how=\"left\"\n",
    ").fillna(\"\")\n",
    "t5 = t5[t5[\"AMA Specialty: AMA Specialty Name\"] != \"\"]\n",
    "p4 = pd.merge_ordered(\n",
    "    p3, ama, left_on=\"code\", right_on=\"Taxonomy Code\", how=\"left\"\n",
    ").fillna(\"\")\n",
    "p4 = p4[p4[\"AMA Specialty: AMA Specialty Name\"] != \"\"]\n",
    "\n",
    "\n",
    "\n",
    "p_cred = pd.Series(p5[\"Provider Credential Text\"].values.flatten())\n",
    "p_spec = pd.Series(p5[\"Classification\"].values.flatten())\n",
    "p5[\"PT\"] = \"MD\"\n",
    "\n",
    "p5[\"PT\"].mask(p_cred.str.contains(r\"DO\", regex=True), \"DO\", inplace=True)\n",
    "p5[\"PT\"].mask(p_spec.str.contains(r\"Physician Assistant\"), \"PA\", inplace=True)\n",
    "p5[\"PT\"].mask(p_spec.str.contains(r\"Nurse Practitioner\"), \"NP\", inplace=True)\n",
    "p5[\"PT\"].mask(p_spec.str.contains(r\"Podiatrist\"), \"DPM\", inplace=True)\n",
    "p5[\"PT\"].mask(p_spec.str.contains(r\"Nurse Anesthetist\"), \"CRNA\", inplace=True)\n",
    "p5[\"PT\"].mask(p_cred.str.contains(r\"MD|M.D\"), \"MD\", inplace=True)\n",
    "p5[\"Gender\"] = p5[\"Gender\"].replace({\"F\": \"Female\", \"M\": \"Male\"})\n",
    "aq = pd.Series(p5[\"Acquisition Source\"].values.flatten())\n",
    "\n",
    "p5[\"Acquisition Source\"].mask(\n",
    "    p5[\"Acquisition Source\"] == \"\", \"Data Source\", inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# up1.to_csv(\"920up1.csv\", index=False)\n",
    "# in1.to_csv(\"920in1.csv\", index=False)\n",
    "# acup1.to_csv(\"920acup1.csv\", index=False)\n",
    "# t5.to_csv(\"920t5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "up1.to_csv(\"920up1.csv\", index=False)\n",
    "in1.to_csv(\"920in1.csv\", index=False)\n",
    "acup1.to_csv(\"920acup1.csv\", index=False)\n",
    "t5.to_csv(\"920t5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "acct = acct[acct[\"Person Account: Email\"] != \"\"]\n",
    "lede = lede[lede[\"Email\"] != \"\"]\n",
    "users = [\n",
    "    \"0056g000005Yehu\",\n",
    "    \"0056g0000066eOF\",\n",
    "    \"0056g0000066eOY\",\n",
    "    \"0056g0000066eOZ\",\n",
    "    \"0056g0000066eOn\",\n",
    "    \"0056g000006LhyP\",\n",
    "    \"0056g000006Mvn5\",\n",
    "    \"0056g0000073I1s\",\n",
    "    \"0055b00000Q6RCr\",\n",
    "]\n",
    "\n",
    "# Distribute values based on colomn len\n",
    "aaaa[\"User\"] = (\n",
    "    pd.np.tile(users, len(aaaa) // len(users)).tolist()\n",
    "    + users[: len(aaaa) % len(users)]\n",
    ")\n",
    "za = aaaa.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross1 = lede[lede[\"NPI\"] != \"\"].drop_duplicates(subset=\"NPI\").fillna(\"\")\n",
    "confid1 = confid[confid[\"File - Email\"] != \"\"].fillna(\"\")\n",
    "# acct = acct[acct['NPI'] != ''].drop_duplicates(subset='NPI')\n",
    "# zb = pd.merge_ordered(za, s1, left_on='code', right_on='Code', how='left').fillna('').astype(object)\n",
    "# z = zb[zb['Specialty: ID'] != '']\n",
    "s1 = (\n",
    "    pd.merge_ordered(za, confid, right_on=\"File - Email\", left_on=\"Email\", how=\"outer\")\n",
    "    .drop_duplicates(subset=\"NPI\")\n",
    "    .fillna(\"\")\n",
    "    .astype(object)\n",
    ")\n",
    "# atte = pd.merge_ordered(atte, user, left_on='User', right_on='Full Name', how='left')\n",
    "# z1 = pd.merge_ordered(za, confid1, left_on='Email', right_on='File - Email', how='left').fillna('').astype(object)\n",
    "s2 = (\n",
    "    pd.merge_ordered(s1, cross1, left_on=\"NPI\", right_on=\"NPI\", how=\"outer\")\n",
    "    .drop_duplicates(subset=\"NPI\")\n",
    "    .fillna(\"\")\n",
    "    .astype(object)\n",
    ")\n",
    "# s4 = pd.merge_ordered(z1, acct, left_on='NPI', right_on='NPI', how='left').drop_duplicates(subset='NPI').fillna('').astype(object)\n",
    "s5 = pd.merge_ordered(\n",
    "    s1, lede, left_on=\"File - Email\", right_on=\"Email\", how=\"left\"\n",
    ").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tax = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\final.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=\"object\",\n",
    ").fillna(\"\")\n",
    "pst = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\spenam.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=\"object\",\n",
    ").fillna(\"\")\n",
    "\n",
    "tax = tax.fillna(\"\")\n",
    "pst = pst.fillna(\"\")\n",
    "\n",
    "tax = tax[tax[\"Specialization\"] != \"\"]\n",
    "pst = pst[pst[\"Specialty: Specialty Name\"] != \"\"]\n",
    "\n",
    "z = pd.merge_ordered(\n",
    "    pst,\n",
    "    tax,\n",
    "    left_on=\"Specialty: Specialty Name\",\n",
    "    right_on=\"Specialization\",\n",
    "    how=\"outer\",\n",
    ").fillna(\"\")\n",
    "# x = pd.merge_ordered(pst, tax, left_on='Residency/Fellowship Specialty', right_on='Specialization', how='left').fillna('')\n",
    "\n",
    "# z = z[(z['Specialty ID'] != '') & (z['Code'] != '')]\n",
    "# x = x[(x['Specialty ID'] != '') & (x['Code'] != '')]\n",
    "#\n",
    "# c = pd.concat([x,z])\n",
    "# c = c.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.fillna(\"\")\n",
    "z[z[\"Code\"] != \"\"].to_csv(\"secs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\june21.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=\"object\",\n",
    ")\n",
    "tax = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\TAX.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=\"object\",\n",
    ")\n",
    "pst = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\pst1.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=\"object\",\n",
    ")\n",
    "# pst1 = pd.merge_ordered(df, tax, on='Code', how='left')\n",
    "pst1 = pst.fillna(\"\")\n",
    "pst2b = pd.merge_ordered(\n",
    "    df, pst1, left_on=\"Specialization\", right_on=\"Sub Specialty\", how=\"left\"\n",
    ")\n",
    "pst2b = pst2b.drop_duplicates(subset=\"number\")\n",
    "pb = pst2b.fillna(\"\")\n",
    "# pb = pst2b[pst2b['Specialty ID'] != '']\n",
    "pst2a = pd.merge_ordered(\n",
    "    df,\n",
    "    pst1,\n",
    "    left_on=\"Specialization\",\n",
    "    right_on=\"Residency/Fellowship Specialty\",\n",
    "    how=\"left\",\n",
    ")\n",
    "pst2a = pst2a.drop_duplicates(subset=\"number\")\n",
    "pa = pst2a.fillna(\"\")\n",
    "# pa = pst2a[pst2a['Specialty ID'] != '']\n",
    "pc = pd.concat([pa, pb])\n",
    "pc_df = pc.drop_duplicates(subset=\"number\").fillna(\"\")\n",
    "pc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst2.to_csv(\"june212.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "file = input(\"Enter file name: \")\n",
    "\n",
    "f = pd.read_json(\n",
    "    f\"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\{file}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = pd.read_csv(\"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\19k.csv\",low_memory=False,\n",
    "# index_col=False, encoding='unicode_escape')\n",
    "g = data_df.fillna(\"\")\n",
    "df = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\TAX.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=\"object\",\n",
    ")\n",
    "acct = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\acct_npi.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    ")\n",
    "cross = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\muhammad.madyun\\\\OneDrive - Hayes Locums\\\\Documents\\\\Data\\\\Analysis\\\\cross_npi.csv\",\n",
    "    low_memory=False,\n",
    "    index_col=False,\n",
    "    encoding=\"unicode_escape\",\n",
    "    dtype=\"object\",\n",
    ")\n",
    "cross = cross.fillna(\"\")\n",
    "cross1 = cross[cross[\"NPI\"] != \"\"]\n",
    "\n",
    "\n",
    "# g = g.drop_duplicates(subset='number')\n",
    "# g = g[(g['code'].isin(df['Code'])) & (~g['number'].isin(acct['NPI']))]\n",
    "g = g.astype(object)\n",
    "f1 = pd.merge_ordered(g, cross1, left_on=\"number\", right_on=\"NPI\", how=\"left\")\n",
    "f2 = pd.merge_ordered(g, acct, left_on=\"number\", right_on=\"NPI\", how=\"left\")\n",
    "f1 = f1.fillna(\"\")\n",
    "f2 = f2.fillna(\"\")\n",
    "f1a = f1[f1[\"Lead Record Id\"] != \"\"]\n",
    "f2a = f2[f2[\"Account Record Id\"] != \"\"]\n",
    "# f.to_csv('19k.csv', index=False)\n",
    "# z = pd.concat([g,f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "get_table(\n",
    "    round,\n",
    "    url=\"https://online.echoboards.org//nbessa//f?p=CRTSSA:17800:11269396482028::::::\",\n",
    ")\n",
    "round_url = f\"{url}/{round}\"\n",
    "page = requests.get(round_url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "rows = []\n",
    "for child in soup.find_all(\"table\")[4].children:\n",
    "    row = []\n",
    "    for td in child:\n",
    "        try:\n",
    "            row.append(td.text.replace(\"\\n\", \"\"))\n",
    "        except:\n",
    "            continue\n",
    "    if len(row) > 0:\n",
    "        rows.append(row)\n",
    "df = pd.DataFrame(rows[1:], columns=rows[0])\n",
    "return df\n",
    "\n",
    "\n",
    "for round in range(1, 39):\n",
    "    table = get_table(round)\n",
    "    table.to_csv(f\"PL_table_matchweek_{round}.csv\", index=False)\n",
    "    sleep(np.random.randint(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of web page to be parsed\n",
    "url = \"https://online.echoboards.org/nbessa/f?p=CRTSSA:17800:11269396482028::::::\"\n",
    "\n",
    "# Make HTTP request to retrieve HTML source of page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML source using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find specific HTML element by tag, class, or ID\n",
    "element = soup.find(\n",
    "    \"table\",\n",
    "    {\n",
    "        \"class\": \"t-Report-report\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Extract element's text or attribute\n",
    "text = element.text\n",
    "attribute = element[\"href\"]\n",
    "# Output results to console\n",
    "\n",
    "print(text)\n",
    "print(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "aa550997-e37b-4a37-9866-c07f3f890c4e",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from salesforce_bulk import SalesforceBulk\n",
    "from salesforce_bulk import CsvDictsAdapter\n",
    "\n",
    "bulk = SalesforceBulk(username=username, password=password)\n",
    "\n",
    "job = bulk.create_insert_job(\"user__c\", contentType=\"CSV\", concurrency=\"Parallel\")\n",
    "\n",
    "reader = csv.DictReader(open(\"user__c.csv\"))\n",
    "disbursals = []\n",
    "for row in reader:\n",
    "    disbursals.append(row)\n",
    "\n",
    "csv_iter = CsvDictsAdapter(iter(disbursals))\n",
    "batch = bulk.post_bulk_batch(job, csv_iter)\n",
    "bulk.wait_for_batch(job, batch)\n",
    "bulk.close_job(job)\n",
    "\n",
    "print(\"Done. Data Uploaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "bbdd77c8-5750-4735-996a-52afb26f873d",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "bulk = SalesforceBulk(username=username, password=password)\n",
    "\n",
    "job = bulk.create_insert_job(\n",
    "    \"custom_object__c\", contentType=\"CSV\", concurrency=\"Parallel\"\n",
    ")\n",
    "\n",
    "disbursals = [dict(Name=\"custoom_object__c%d\" % idx) for idx in xrange(5)]\n",
    "\n",
    "csv_iter = CsvDictsAdapter(iter(disbursals))\n",
    "\n",
    "batch = bulk.post_bulk_batch(job, csv_iter)\n",
    "\n",
    "bulk.wait_for_batch(job, batch)\n",
    "\n",
    "bulk.close_job(job)\n",
    "\n",
    "print(\"Done. Data Uploaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "ff4456f5-11c8-4897-89ad-a6224475108a",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_path = input(\"enter the path to the file you want to open\")\n",
    "for file in file_path:\n",
    "    if file.endswith(\".csv\", \"tsv\"):\n",
    "        df = pd.read_csv(file)\n",
    "        print(df.head(100))\n",
    "    elif file.endswith(\".json\"):\n",
    "        df = pd.read_json(file)\n",
    "        print(df.head(100))\n",
    "    elif file.endswith(\".xml\"):\n",
    "        df = pd.read_xml(file)\n",
    "        print(df.head(100))\n",
    "    elif file.endswith(\".xls\", \"xlsx\"):\n",
    "        df = pd.read_excel(file)\n",
    "        print(df.head(100))\n",
    "    elif file.endswith(\".hdf\"):\n",
    "        df = pd.read_hdf(file)\n",
    "        print(df.head(100))\n",
    "    elif file.endswith(\".sql\"):\n",
    "        df = pd.read_sql(file)\n",
    "        print(df.head(100))\n",
    "    else:\n",
    "        print(\"file format not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "ccfe933e-43fb-4955-ab3b-d4afe0a64bd0",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_any(file):\n",
    "    if file.endswith(\".csv\", \"tsv\"):\n",
    "        df = pd.read_csv(file)\n",
    "    elif file.endswith(\".json\"):\n",
    "        df = pd.read_json(file)\n",
    "    elif file.endswith(\".xml\"):\n",
    "        df = pd.read_xml(file)\n",
    "    elif file.endswith(\".xls\", \"xlsx\"):\n",
    "        df = pd.read_excel(file)\n",
    "    elif file.endswith(\".hdf\"):\n",
    "        df = pd.read_hdf(file)\n",
    "    elif file.endswith(\".sql\"):\n",
    "        df = pd.read_sql(file)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported filetype: {file}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # here or wherever it is used\n",
    "    file_path = input(\"enter the path to the file you want to open\")\n",
    "    df = read_any(file_path)\n",
    "    print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "28c56d6f-28d6-4e25-bbff-5811be520cf1",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "READER_MAP = {\n",
    "    \"xlsx\": pd.read_excel,\n",
    "    \"xls\": pd.read_excel,\n",
    "    \"xml\": pd.read_xml,  # .. and so on\n",
    "    \"sql\": my_read_sql,  # special case\n",
    "}\n",
    "\n",
    "\n",
    "def my_read_sql(con_w_sql, sep=\"#\"):\n",
    "    \"\"\"Made-up function that reads SQL from CON in a single call\n",
    "\n",
    "    Args:\n",
    "        con_w_sql: connection string + query or table name,\n",
    "            joined by separator string sep\n",
    "        sep: separator\n",
    "\n",
    "    Example:\n",
    "        >>> my_read_sql('postgres:///db_name#table_name')\n",
    "    \"\"\"\n",
    "    con, sql = special_path.split(sep)\n",
    "    return pd.read_sql(sql, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "649a68f7-d007-4b20-afcc-0616cea89b7e",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def read_any(file):\n",
    "    _, ext = os.path.splitext(file)\n",
    "    try:\n",
    "        reader = READER_MAP[ext]\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Unsupported filetype: {ext}\")\n",
    "    return reader(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "e53e9c4f-0b99-49d6-bf95-ec89b9465611",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file.endswith((\".csv\", \".tsv\"))\n",
    "# this is correct\n",
    "file.endswith(\".csv\", \".tsv\")\n",
    "# this is wrong\n",
    "\n",
    "\n",
    "file_path = input(\"enter the path to the file you want to open\")\n",
    "b = os.listdir(file_path)\n",
    "for file in b:\n",
    "    path = file_path + file\n",
    "    df = pd.read_csv(path) if file.endswith((\".csv\", \".tsv\")) else None\n",
    "    df = pd.read_json(file) if file.endswith(\".json\") else df\n",
    "    df = pd.read_xml(file) if file.endswith(\".xml\") else df\n",
    "    df = pd.read_excel(file) if file.endswith((\".xls\", \"xlsx\")) else df\n",
    "    df = pd.read_hdf(file) if file.endswith(\".hdf\") else df\n",
    "    df = pd.read_sql(file) if file.endswith(\".sql\") else df\n",
    "    if file.endswith(\n",
    "        (\".csv\", \".tsv\", \".json\", \".xml\", \".xls\", \".xlxs\", \".hdf\", \".sql\")\n",
    "    ):\n",
    "        print(df.head(100))\n",
    "    else:\n",
    "        print(\"format not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "3f04b8e3-f2d3-4db9-a4d4-d817ff2bc52a",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import modin.pandas as pd\n",
    "import json\n",
    "import featuretools as ft\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from distributed import Client\n",
    "\n",
    "\n",
    "def sqlread(con_w_sql, sep=\"#\"):\n",
    "    con, sql = special_path.split(sep)\n",
    "    df = pd.read_sql(sql, con)\n",
    "    return df.head()\n",
    "\n",
    "\n",
    "readict = {\n",
    "    \".csv\": {\"read\": pd.read_csv},\n",
    "    \".tsv\": {\"read\": pd.read_csv},\n",
    "    \".json\": {\"read\": pd.read_json},\n",
    "    \".xlsx\": {\"read\": pd.read_excel},\n",
    "    \".xml\": {\"read\": pd.read_xml},\n",
    "    \".xls\": {\"read\": pd.read_excel},\n",
    "    \".hdf\": {\"read\": pd.read_hdf},\n",
    "    \".sql\": {\"read\": sqlread},\n",
    "}\n",
    "\n",
    "\n",
    "def read_any(file):\n",
    "    _, ext = os.path.splitext(file)\n",
    "    df = readict[ext][\"read\"](file)\n",
    "    es = ft.EntitySet()\n",
    "    es = es.entity_from_dataframe(entity_id=\"df\", dataframe=df)\n",
    "    head = df.head(100).values.tolist()\n",
    "    dtype = es[\"df\"]\n",
    "\n",
    "    dtypedict = dtype.variable_types\n",
    "    types = []\n",
    "\n",
    "    for value in dtypedict.values():\n",
    "        types.append(value.type_string)\n",
    "\n",
    "    return json.dumps(head), json.dumps(types)\n",
    "\n",
    "\n",
    "file = input(\"enter the path to the file you want to open : \")\n",
    "read_any(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
